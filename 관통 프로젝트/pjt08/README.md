# pjt08_231103

# PJT08

# A. CSV 데이터를 DataFrame으로 변환 후 반환

```python
# CSV 파일 읽어와 데이터프레임으로 저장 (서버 시작 시에 한 번만 읽어옴)
csv_path = './data/test_data.csv'
g_df = pd.read_csv(csv_path, encoding='cp949')
```

- csv로 불러온 같은 파일을 계속해서 반복적으로 사용하기 때문에 전역변수로 설정하여 global dataframe을 저장하였다.

```python
def CSV_to_DF(request):
# CSV 파일 읽어오기
    data = g_df.to_dict('records')
    return JsonResponse({ 'dat' : data }, json_dumps_params={'ensure_ascii': False})
```

- CSV로 불러온 파일을 Json데이터로 변환하여 return 한다

# B. 결측치 처리 후 데이터 반환

- 비어 있는 값을 'NULL' 문자열로 치환 후 DataFrame을 반환한다

```python
def missingValues(request):
    # 결측값은 null로 채워서 반환
    df_filled = g_df.fillna('NULL')
    data = df_filled.to_dict('records')

    return JsonResponse({'dat': data})
```

# C. 알고리즘 구현하기(평균 나이와 가장 비슷한 10명)

```python
from django.views.decorators.cache import cache_page
from django.core.cache import cache

@cache_page(60 * 2)
def avg_ages(request):
    cache_key = 'avg_ages_result'
    cached_result = cache.get(cache_key)

    if cached_result is None:
        # 캐시가 없는 경우 계산하고 결과를 캐싱
        avg_age = g_df['나이'].mean()
        similar_ages_df = g_df.iloc[(g_df['나이'] - avg_age).abs().argsort()[:10]]
        data = similar_ages_df.to_dict('records')
        cache.set(cache_key, data, 60 * 15)  # 15분 동안 캐싱

    else:
        # 캐시가 있는 경우 캐시된 결과를 사용
        data = cached_result

    return JsonResponse({'dat': data})
```

## C-1 정렬

- 기존 코드는 '나이차이'라는 열을 새로 만든 다음에 그 열을 기준으로 정렬하는 방식이었지만 그렇게 되면 불필요한 데이터프레임의 열이 추가 되어 메모리 사용량이 증가하는 문제점이 있었다. 따라서 abs(g_df['나이'] - avg_age)의 결과를 바로 정렬하고 인덱스를 가져오는 방식으로 변경하였다.

- 정렬된 인덱스를 사용하여 원본 데이터프레임에서 직접 행을 선택하여 추가적인 데이터프레임 생성과정을 생략하고 메모리 사용량과 연산 시간을 줄이려고 하였다.

- 나이 순대로 정렬하는 부분에서 어떻게 개선할 수 있을지 고민했다. 하지만 파이썬에 내장되어 있는 정렬메서드가 내가 직접 구현한 정렬 알고리즘보다 훨씬 효율적이라는 것을 알게 되어서 정렬 알고리즘 이외에 다른 부분에서 성능을 개선할 수 있을지 고민해보았다.

- 최종 버전에서는 argsort() 함수를 사용하여 나이와 평균 나이 차이를 계산하고 정렬한 후 인덱스를 가져와서 10개의 행을 선택하였다. 이 함수를 사용하면 코드가 간결해질 뿐만 아니라 중간 결과를 만드는데 필요한 중간 데이터 구조를 줄일 수 있다고 한다.

## C-2 서버 최적화 방법

- 위의 코드를 가지고 테스트를 한 결과 50%의 요청은 10초 이내에 응답되지만, 99%의 요청은 22초 이내에 응답되었다. 서버가 일부 요청에 대해 매우 느리게 응답하는 것을 확인하고 다른 최적화 방법을 조사해보았다.

- 다른 개선할 수 있는 방법으로는
  
  > 1. **서버 최적화**: 서버 측면에서 성능 향상을 위해 코드를 최적화하고 쿼리 성능을 향상시키는 등의 작업. Django 애플리케이션의 코드와 데이터베이스 쿼리를 검토하여 병목 현상을 찾고 최적화하기
  > 
  > 2. **코드 프로파일링**: 코드 프로파일링을 통해 애플리케이션에서 성능 문제를 일으키는 부분을 찾고 최적화.
  > 
  > 3. **데이터베이스 인덱싱**: 데이터베이스에서 사용되는 필드에 인덱스를 추가하여 쿼리 성능을 향상. 데이터베이스 스키마와 쿼리를 검토.
  > 
  > 4. **캐싱 적용**: 캐싱을 통해 빈번하게 요청되는 데이터나 결과를 메모리에 저장해두고 다시 계산하지 않도록 할 수 있다. 이는 응답 시간을 크게 줄일 수 있습니다.
  > 
  > 5. **비동기 처리**: Django에서 비동기 처리를 지원하는 미들웨어를 사용하여 I/O 바운드 작업을 비동기적으로 처리하면 서버 응답 시간을 향상시킬 수 있음.
  > 
  > 6. **로드 밸런싱 및 확장**: 여러 서버 인스턴스를 사용하여 로드 밸런싱을 설정하고, 필요하다면 서버를 수평으로 확장하여 트래픽을 분산시킬 수 있음. 이는 서버의 부하를 줄이고 성능을 향상시킬 수 있음.

- 그러나 위의 방법 중 대부분은 쿼리, 기본 세팅 등에 관련된 부분이 많아서 이번 프로젝트에 사용하기 어려운 방법들이었다. 

- Django에서 캐싱을 적용하는 방법을 찾아본 결과 **케시 데코레이터**를 알게 되었다.
  
  - Django는 `cache_page` 데코레이터를 제공하여 특정 뷰 함수의 결과를 캐싱할 수 있다. 이 데코레이터는 특정 시간 동안 결과를 캐싱하거나, 특정 조건이 충족될 때까지 캐싱된 결과를 반환할 수 있다.
  
  - 밑 코드는 `avg_ages` 뷰의 결과를 15분 동안 캐싱한다
  
  ```python
  from django.views.decorators.cache import cache_page
  
  @cache_page(60 * 15)  # 15분 동안 캐싱
  @api_view(['GET'])
  def avg_ages(request):
      # 함수 내용은 여전히 유지됨
  ```

- **캐시 API 사용**: Django는 캐시 API를 제공하여 코드 내에서 직접 캐싱을 조작할 수 있다.
  
  - 먼저 캐시에서 결과를 가져오고, 캐시가 없는 경우 계산한 뒤 결과를 캐싱한다. 이렇게 함으로써 캐시 미스 시에만 계산하고 나머지 경우에는 캐시된 결과를 사용할 수 있다.

```python
from django.core.cache import cache

cached_result = cache.get(cache_key) # 사용법
```

| 총 접속자 | 동시 접속자 | 평균 RPS : 요청 응답 수 | 50%lie | 95%lie | 99%lie | 100%lie | 비고   |
| ----- | ------ | ---------------- | ------ | ------ | ------ | ------- | ---- |
| 5000  | 100    | 422.6            | 9300   | 10000  | 11000  | 22000   | 원래코드 |
| 5000  | 100    | 730              | 950    | 2000   | 12000  | 56000   | 캐싱   |

- 결론 : 컴퓨터 상황에 따라 약간의 차이를 보였지믄  평균 RPS의 경우 캐싱을 했을 때 약 2배 정도 증가하였다. 초당 요청 수가 유의미하게 증가한 것을 보아 성능이 개선되었음을 확인할 수 있다.

---

# TIL

- [1. 테스트란?](#1-테스트란)
- [2. 성능 테스트](#2-성능-테스트)
  - [2-1 부하테스트](#2-1-부하테스트)
  - [2-2 스트레스 테스트](#2-2-스트레스-테스트)
- [3.  API 성능 테스트](#3--api-성능-테스트)

# 1. 테스트란?

1. 원하는 기능이 모두 구현되었는지 확인하고,
2. 숨겨진 결함을 찾는 활동
   - 여러 도구를 활용하여 버그를 찾아내고 신뢰성, 보안, 성능 등을 검증하는 중요한 단계

> 참고하면 좋을 자료: 소프트웨어 테스트 표준, 마틴 파울러 테스트 피라미드

# 2. 성능 테스트

- 특정 상황에서 시스템이 어느 정도 수준을 보이는가 혹은 어떻게 대처하는가를 테스트하는 과정
- 목적
  - 여러 테스트를 통해 성능 저하가 발생하는 요인을 발견하고 제거
  - 시장에 출시되기 전에 발생할 수 있는 위험과 개선사항 파악
  - - 안정적이고 신뢰할 수 있는 제품 빠르게 하기 위함

## 2-1 부하테스트

- 시스템 임계점의 부하가 계속될 때 문제가 없는가?
- 목적: 시스템의 신뢰도와 성능을 측정
- 결과
  - 부하 분산 문제
  - 최대 성능
  - 시간 당 서버 처리량 및 응답 시간

## 2-2 스트레스 테스트

- 시스템에 과부하가 오면?
- 장애 조치와 복구 절차가 효과적이고 효율적인지 확인하는 목적
- 어떻게 대처하는가
- 결과
  - 안정성
  - 복구 가능성

|       | 부하 테스트(Load Testing)      | 스트레스 테스트(Stress Testing) |
| ----- | ------------------------- | ------------------------ |
| 도메인   | 성능 테스트의 하위 집합             | 성능 테스트의 하위 집합            |
| 목적    | 전체 시스템의 성능 확인             | 중단점에서의 동작, 복구 가능성 확인     |
| 방법    | 임계점까지의 가상 유저 수를 유지하며 모니터링 | 중단점 이상까지 가상 유저를 점진적으로 증가 |
| 대상    | 전체 시스템                    | 식별된 트랜잭션에만 집중하여 테스트      |
| 완료 시기 | 예상 부하가 모두 적용된 경우          | 시스템 동작이 중단되었을 경우         |

# 3.  API 성능 테스트

- 오픈 소스 부하 테스트 도구

- 내가 만든 서버에 수많은 사용자들이 동시에 들어올 때 어떤 일이 벌어지는 지를 확인하는 부하테스트 도구

- 선택 이유
  
  - 파이썬 언어로 테스트 시나리오를 간편하게 작성할 수 있다
  
  - 결과를 웹에서 확인할 수 있는 UI를 지원한다

- 방법
1. 테스트 스크립트 작성
   
   > - HttpUser : HTTP 요청을 만드는 가상 유저
   > 
   > - wait_time : 작업 간 대기 시간
   > 
   > - on_start() : 가상 유저 생성 시 실행
   > 
   > - @task : 유저가 실행할 작업
   > 
   > - @task(N) : 가중치 (실행 확률)
   >   
   >   - N 만큼 높은 확률로 작업을 수행
   > 
   > - self.client.get : HTTP GET 요청 전송

2. Django 서버 실행

3. Locust 설치 및 실행
   
   ```bash
   (venv) $ pip install locust
   (venv) $ locust -f ./locust_test.py
   ```
   
   http://localhost:8089 로 접속

4. 사용법

> Number of users : 생성할 총 가상유저 수
> 
> Spawn rate : 동시에 접속하는 유저 수
> 
> Host : 서버 주소

- chart
  
  > Total Request per Second
  > 
  > - 초록색 : 초당 요청 수(RPS)
  > 
  > - 빨간선 : 초당 실패한 요청 수
  > 
  > Response Time(ms)
  > 
  > - 각 응답에 대한 평균 응답 시간
  > 
  > - 노란선(95) : 95%의 응답이 해당 시간 내에 처리되었다
  > 
  > - 초록선(Mediean) : 응답 시간의 중앙값
  > 
  > Number of Users
  > 
  > - 동시에 요청을 보내는 유저 수

----

- JSON vs CSV

| 특징     | JSON                              | CSV                                                           |
| ------ | --------------------------------- | ------------------------------------------------------------- |
| 장점     | 모양과 규칙 자체가 단순해서 타 언어에서도 구현하기가 쉽다  | 용량 작다, 변하지 않는 많은 양의 데이터를 제공할 때 주로 이용이 가능하다                    |
| 단점     | 콤마가 누락되거나 중괄호가 잘못 닫히는 등 문법 오류에 취약 | 데이터의 의미를 표시할 수 업식 때문에 데이터가 많아지면 어떤 데이터가 항목을 나타내는지 직관적인 이해 어려움 |
| 주요 사용처 | 서버통신 REST API                     | 간단한 테이블 작성, 읽는 속도 중요한 부분                                      |